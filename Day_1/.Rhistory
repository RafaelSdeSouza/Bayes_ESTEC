new.N = length(time),
minD = min(y)
)
Exp <- "model{
lambda <- 1/theta
theta ~ dnorm(0,0.001)T(,minD)                                        # standard deviation
# Likelihood function
for (i in 1:N){
Y[i] ~ dexp(lambda)
}
# Prediction
for (i in 1:new.N ){
S.t[i] <- exp(-(new.t[i])/theta)
}
}"
inits <- function() {
list(theta = runif(1, 0, 10))
}
params <- c("theta","S.t")
Surv_fit <- jags(data = model.data,
inits = inits,
parameters.to.save  = params,
model.file = textConnection(Exp),
n.chains = 3,
n.iter = 5000,
n.thin = 1,
n.burnin = 1000)
S <- ggs(as.mcmc(Surv_fit)) %>%
filter(.,Parameter == "theta")
ggplot(S,aes(x=value)) +
geom_histogram(fill = "#f4901e",bins= 50,aes(y=..count../sum(..count..))) +
theme_xkcd() +
xlab(expression(theta)) +
ylab("Frequency")
hist(y)
model.data
# Construct data dictionary
model.data <- list(Y = y,                               # Response variable
N = nobs,                           # Sample size
minD = min(y)
)
Exp <- "model{
lambda <- 1/theta
theta ~ dnorm(0,0.001)T(,minD)                                        # standard deviation
# Likelihood function
for (i in 1:N){
Y[i] ~ dexp(lambda)
}
}"
inits <- function() {
list(theta = runif(1, 0, 10))
}
params <- c("theta","S.t")
Surv_fit <- jags(data = model.data,
inits = inits,
parameters.to.save  = params,
model.file = textConnection(Exp),
n.chains = 3,
n.iter = 5000,
n.thin = 1,
n.burnin = 1000)
S <- ggs(as.mcmc(Surv_fit)) %>%
filter(.,Parameter == "theta")
ggplot(S,aes(x=value)) +
geom_histogram(fill = "#f4901e",bins= 50,aes(y=..count../sum(..count..))) +
theme_xkcd() +
xlab(expression(theta)) +
ylab("Frequency")
params <- c("theta")
Surv_fit <- jags(data = model.data,
inits = inits,
parameters.to.save  = params,
model.file = textConnection(Exp),
n.chains = 3,
n.iter = 5000,
n.thin = 1,
n.burnin = 1000)
S <- ggs(as.mcmc(Surv_fit)) %>%
filter(.,Parameter == "theta")
ggplot(S,aes(x=value)) +
geom_histogram(fill = "#f4901e",bins= 50,aes(y=..count../sum(..count..))) +
theme_xkcd() +
xlab(expression(theta)) +
ylab("Frequency")
# Confidence vs Bayesian intervals
# Truncated exponential
require(ggplot2)
require(xkcd)
require(R2jags)
require(mdatools)
require(ggmcmc)
source("https://raw.githubusercontent.com/johnbaums/jagstools/master/R/jagsresults.R")
###  Plot truncated exponential
p_exp <- Vectorize(function(x,theta){
if(x > theta){
return(exp(theta-x))
} else
return(0)
}
)
x <- seq(5,18,length.out = 1e3)
g <- data.frame(x=x,y=p_exp(x,10))
ggplot(g,aes(x=x,y=y)) +
geom_line() +
geom_area(fill="#f4901e") +
theme_xkcd() +
xlab("Failiture time") +
ylab("px")
######
# Simulate truncated exponential
y <- c(10,rexp(100) + 10) # Maybe there is a better way of doing this.
#The first 10 ensures to have one single observation equal to theoretical minimum to test the
#Frequentist and Bayesian approach against a hard coded scenario
nobs <- length(y)
# Check
hist(y)
#y <- c(10,12,15)
# Fit a survival model
SurvObj <-  Surv(time=y)
model.par <- survreg(SurvObj~1, dist="exponential")
mu = exp(model.par$coeff)
# Confidence intervals
approx_CI <- function(D,sig=0.95){
Nsigma = sqrt(2)*erfinv(sig)
N = length(D)
theta_hat <- mean(D) - 1
return(list(CI_U = theta_hat+Nsigma/sqrt(N),CI_L=theta_hat-Nsigma/sqrt(N)))
}
approx_CI(y)
#CI <- exp(confint(model.par))
#print(CI)
# Bayesian solution
# Construct data dictionary
model.data <- list(Y = y,                               # Response variable
N = nobs,                           # Sample size
minD = min(y)
)
Exp <- "model{
lambda <- 1/theta
theta ~ dnorm(0,0.001)T(,minD)                                        # standard deviation
# Likelihood function
for (i in 1:N){
Y[i] ~ dexp(lambda)
}
}"
inits <- function() {
list(theta = runif(1, 0, 10))
}
params <- c("theta")
Surv_fit <- jags(data = model.data,
inits = inits,
parameters.to.save  = params,
model.file = textConnection(Exp),
n.chains = 3,
n.iter = 5000,
n.thin = 1,
n.burnin = 1000)
S <- ggs(as.mcmc(Surv_fit)) %>%
filter(.,Parameter == "theta")
ggplot(S,aes(x=value)) +
geom_histogram(fill = "#f4901e",bins= 50,aes(y=..count../sum(..count..))) +
theme_xkcd() +
xlab(expression(theta)) +
ylab("Frequency")
N = 5
Nsamp = 1000
sigma_x = 2
x <- matrix(rnorm(Nsamp*5, 0, 2), ncol = 5)
mu_samp = rowMeans(x)
x
N = 5
Nsamp = 1000
sigma_x = 2
x <- matrix(rnorm(Nsamp*5, 0, 2), ncol = 5)
mu_samp = rowMeans(x)
# Formula
sig_samp = sigma_x/sqrt(N)
cat(sig_samp, "approximates", sd(mu_samp))
true_B = 100
sigma_x = 10
set.seed(1)
D = rnorm(3,true_B, sigma_x)
print(D)
freq_CI_mu <- function(D,sigma,frac=0.95){
Nsigma = sqrt(2)*erfinv(frac)
mu = mean(D)
sigma_mu = sigma/sqrt(length(D))
return(c(mu - Nsigma * sigma_mu, mu + Nsigma * sigma_mu))
}
freq_CI_mu(D,sigma_x)
bayes_CR_mu <- function(D, sigma, frac=0.95){
Nsigma = sqrt(2)*erfinv(frac)
mu = mean(x)
sigma_mu = sigma/sqrt(length(D))
return(c(mu - Nsigma * sigma_mu, mu + Nsigma * sigma_mu))
}
bayes_CR_mu(D,sigma_x)
freq_CI_mu(D,sigma_x)
bayes_CR_mu <- function(D, sigma, frac=0.95){
Nsigma = sqrt(2)*erfinv(frac)
mu = mean(x)
sigma_mu = sigma/sqrt(length(D))
return(c(mu - Nsigma * sigma_mu, mu + Nsigma * sigma_mu))
}
bayes_CR_mu(D,sigma_x)
freq_CI_mu(D,sigma_x)
true_B = 100
sigma_x = 10
set.seed(1)
D = rnorm(3,true_B, sigma_x)
print(D)
freq_CI_mu <- function(D,sigma,frac=0.95){
Nsigma = sqrt(2)*erfinv(frac)
mu = mean(D)
sigma_mu = sigma/sqrt(length(D))
return(c(mu - Nsigma * sigma_mu, mu + Nsigma * sigma_mu))
}
freq_CI_mu(D,sigma_x)
bayes_CR_mu <- function(D, sigma, frac=0.95){
Nsigma = sqrt(2)*erfinv(frac)
mu = mean(x)
sigma_mu = sigma/sqrt(length(D))
return(c(mu - Nsigma * sigma_mu, mu + Nsigma * sigma_mu))
}
bayes_CR_mu(D,sigma_x)
bayes_CR_mu <- function(D, sigma, frac=0.95){
Nsigma = sqrt(2)*erfinv(frac)
mu = mean(D)
sigma_mu = sigma/sqrt(length(D))
return(c(mu - Nsigma * sigma_mu, mu + Nsigma * sigma_mu))
}
bayes_CR_mu(D,sigma_x)
pwd
setwd("~/Documents/GitHub/Bayes_ESTEC/Day_1")
getwd()
# ADA8 – Astronomical Data Analysis Summer School
# Bayesian tutorial by Rafael S. de Souza - ELTE, Hungary & COIN
#
# Partial example from Bayesian Models for Astrophysical Data
# by Hilbe, de Souza & Ishida, 2016, Cambridge Univ. Press
#
# Example of Bayesian normal linear regression in R using JAGS
# synthetic data
# 1 response (y) and 1 explanatory variable (x1)
require(R2jags)
source("..//Auxiliar_functions/jagsresults.R")
require(ggplot2)
set.seed(1056)                 # set seed to replicate example
nobs= 500                      # number of obs in model
x1 <- runif(nobs,2,5)          # random uniform variable
xb <- 2 + 3*x1                 # linear predictor
y <- rnorm(nobs, xb, sd=2)     # create y as adjusted random normal variate
plot(x1,y)
# Prepare data for prediction
M=500
xx = seq(from =  min(x1),
to =  max(x1),
length.out = M)
# prepare data for JAGS input
#X <- model.matrix(~ 1 + x1)
#K <- ncol(X)
jags_data <- list(Y = y,
X  = x1,
K  = 2,
N  = nobs,
M = M,
xx= xx)
# JAGS model
NORM <-" model{
# Diffuse normal priors for predictors
for (i in 1:K) { beta[i] ~ dnorm(0, 0.0001) }
# Uniform prior for standard deviation
sigma ~ dunif(0, 100)       # standard deviation
tau <- pow(sigma, -2)       # precision
# Likelihood function
for (i in 1:N){
Y[i]~dnorm(mu[i],tau)
mu[i]  <- eta[i]
eta[i] <- beta[1]+beta[2]*X[i]
}
# Prediction for new data
for (j in 1:M){
etax[j]<-beta[1]+beta[2]*xx[j]
mux[j]  <- etax[j]
Yx[j]~dnorm(mux[j],tau)
}
}"
# set initial values
inits <- function () {
list(
beta = rnorm(2, 0, 0.01))
}
# define parameters
params <- c("beta", "sigma","Yx")
#params <- c("beta", "sigma")
jagsfit <- jags(
data       = jags_data,
inits      = inits,
parameters = params,
model      = textConnection(NORM),
n.chains   = 3,
n.iter     = 5000,
n.thin     = 1,
n.burnin   = 2500)
require(mcmcplots)
traplot(jagsfit)
denplot(jagsfit)
#print(jagsfit,justify = "left", digits=2)
# Plot
yx <- jagsresults(x=jagsfit, params=c('Yx'))
#S<-ggs(as.mcmc(jagsfit))
ggs_pairs(ggs(S))
normdata <- data.frame(x1,y)
gdata <- data.frame(x =xx, mean = yx[,"mean"],lwr1=yx[,"25%"],lwr2=yx[,"2.5%"],upr1=yx[,"75%"],upr2=yx[,"97.5%"])
ggplot(normdata,aes(x=x1,y=y))+ geom_point(colour="#de2d26",size=1,alpha=0.35)+
geom_point(size=1.5,colour="red3")+
geom_ribbon(data=gdata,aes(x=xx,ymin=lwr1, ymax=upr1,y=NULL), alpha=0.95, fill=c("orange3"),show.legend=FALSE) +
geom_ribbon(data=gdata,aes(x=xx,ymin=lwr2, ymax=upr2,y=NULL), alpha=0.35, fill = c("orange"),show.legend=FALSE) +
geom_line(data=gdata,aes(x=xx,y=mean),colour="gray25",linetype="dashed",size=1,show.legend=FALSE)+
theme_bw()
# ADA8 – Astronomical Data Analysis Summer School
# Bayesian tutorial by Rafael S. de Souza - ELTE, Hungary & COIN
#
# Partial example from Bayesian Models for Astrophysical Data
# by Hilbe, de Souza & Ishida, 2016, Cambridge Univ. Press
#
# Example of Bayesian normal linear regression in R using JAGS
# synthetic data
# 1 response (y) and 1 explanatory variable (x1)
require(R2jags)
source("..//Auxiliar_functions/jagsresults.R")
require(ggplot2)
set.seed(1056)                 # set seed to replicate example
nobs= 500                      # number of obs in model
x1 <- runif(nobs,2,5)          # random uniform variable
xb <- 2 + 3*x1                 # linear predictor
y <- rnorm(nobs, xb, sd=2)     # create y as adjusted random normal variate
plot(x1,y)
# Prepare data for prediction
M=500
xx = seq(from =  min(x1),
to =  max(x1),
length.out = M)
# prepare data for JAGS input
#X <- model.matrix(~ 1 + x1)
#K <- ncol(X)
jags_data <- list(Y = y,
X  = x1,
K  = 2,
N  = nobs,
M = M,
xx= xx)
# JAGS model
NORM <-" model{
# Diffuse normal priors for predictors
for (i in 1:K) { beta[i] ~ dnorm(0, 0.0001) }
# Uniform prior for standard deviation
sigma ~ dunif(0, 100)       # standard deviation
tau <- pow(sigma, -2)       # precision
# Likelihood function
for (i in 1:N){
Y[i]~dnorm(mu[i],tau)
mu[i]  <- eta[i]
eta[i] <- beta[1]+beta[2]*X[i]
}
# Prediction for new data
for (j in 1:M){
etax[j]<-beta[1]+beta[2]*xx[j]
mux[j]  <- etax[j]
Yx[j]~dnorm(mux[j],tau)
}
}"
# set initial values
inits <- function () {
list(
beta = rnorm(2, 0, 0.01))
}
# define parameters
params <- c("beta", "sigma","Yx")
#params <- c("beta", "sigma")
jagsfit <- jags(
data       = jags_data,
inits      = inits,
parameters = params,
model      = textConnection(NORM),
n.chains   = 3,
n.iter     = 5000,
n.thin     = 1,
n.burnin   = 2500)
# Plot
yx <- jagsresults(x=jagsfit, params=c('Yx'))
normdata <- data.frame(x1,y)
gdata <- data.frame(x =xx, mean = yx[,"mean"],lwr1=yx[,"25%"],lwr2=yx[,"2.5%"],upr1=yx[,"75%"],upr2=yx[,"97.5%"])
ggplot(normdata,aes(x=x1,y=y))+ geom_point(colour="#de2d26",size=1,alpha=0.35)+
geom_point(size=1.5,colour="red3")+
geom_ribbon(data=gdata,aes(x=xx,ymin=lwr1, ymax=upr1,y=NULL), alpha=0.95, fill=c("orange3"),show.legend=FALSE) +
geom_ribbon(data=gdata,aes(x=xx,ymin=lwr2, ymax=upr2,y=NULL), alpha=0.35, fill = c("orange"),show.legend=FALSE) +
geom_line(data=gdata,aes(x=xx,y=mean),colour="gray25",linetype="dashed",size=1,show.legend=FALSE)+
theme_bw()
source("..//Auxiliar_functions/jagsresults.R")
# define parameters
params <- c("beta", "sigma","Yx","mux")
#params <- c("beta", "sigma")
jagsfit <- jags(
data       = jags_data,
inits      = inits,
parameters = params,
model      = textConnection(NORM),
n.chains   = 3,
n.iter     = 5000,
n.thin     = 1,
n.burnin   = 2500)
# Plot
yx <- jagsresults(x=jagsfit, params=c('mux'))
normdata <- data.frame(x1,y)
gdata <- data.frame(x =xx, mean = yx[,"mean"],lwr1=yx[,"25%"],lwr2=yx[,"2.5%"],upr1=yx[,"75%"],upr2=yx[,"97.5%"])
ggplot(normdata,aes(x=x1,y=y))+ geom_point(colour="#de2d26",size=1,alpha=0.35)+
geom_point(size=1.5,colour="red3")+
geom_ribbon(data=gdata,aes(x=xx,ymin=lwr1, ymax=upr1,y=NULL), alpha=0.95, fill=c("orange3"),show.legend=FALSE) +
geom_ribbon(data=gdata,aes(x=xx,ymin=lwr2, ymax=upr2,y=NULL), alpha=0.35, fill = c("orange"),show.legend=FALSE) +
geom_line(data=gdata,aes(x=xx,y=mean),colour="gray25",linetype="dashed",size=1,show.legend=FALSE)+
theme_bw()
set.seed(1056)                 # set seed to replicate example
nobs= 100                      # number of obs in model
x1 <- rnorm(nobs,3,1)          # random uniform variable
xb <- 2 + 3*x1                 # linear predictor
y <- rnorm(nobs, xb, sd=2)     # create y as adjusted random normal variate
plot(x1,y)
# Prepare data for prediction
M=500
xx = seq(from =  min(x1),
to =  max(x1),
length.out = M)
# prepare data for JAGS input
#X <- model.matrix(~ 1 + x1)
#K <- ncol(X)
jags_data <- list(Y = y,
X  = x1,
K  = 2,
N  = nobs,
M = M,
xx= xx)
# JAGS model
NORM <-" model{
# Diffuse normal priors for predictors
for (i in 1:K) { beta[i] ~ dnorm(0, 0.0001) }
# Uniform prior for standard deviation
sigma ~ dunif(0, 100)       # standard deviation
tau <- pow(sigma, -2)       # precision
# Likelihood function
for (i in 1:N){
Y[i]~dnorm(mu[i],tau)
mu[i]  <- eta[i]
eta[i] <- beta[1]+beta[2]*X[i]
}
# Prediction for new data
for (j in 1:M){
etax[j]<-beta[1]+beta[2]*xx[j]
mux[j]  <- etax[j]
Yx[j]~dnorm(mux[j],tau)
}
}"
# set initial values
inits <- function () {
list(
beta = rnorm(2, 0, 0.01))
}
# define parameters
params <- c("beta", "sigma","Yx","mux")
#params <- c("beta", "sigma")
jagsfit <- jags(
data       = jags_data,
inits      = inits,
parameters = params,
model      = textConnection(NORM),
n.chains   = 3,
n.iter     = 5000,
n.thin     = 1,
n.burnin   = 2500)
# Plot
yx <- jagsresults(x=jagsfit, params=c('mux'))
normdata <- data.frame(x1,y)
gdata <- data.frame(x =xx, mean = yx[,"mean"],lwr1=yx[,"25%"],lwr2=yx[,"2.5%"],upr1=yx[,"75%"],upr2=yx[,"97.5%"])
ggplot(normdata,aes(x=x1,y=y))+ geom_point(colour="#de2d26",size=1,alpha=0.35)+
geom_point(size=1.5,colour="red3")+
geom_ribbon(data=gdata,aes(x=xx,ymin=lwr1, ymax=upr1,y=NULL), alpha=0.95, fill=c("orange3"),show.legend=FALSE) +
geom_ribbon(data=gdata,aes(x=xx,ymin=lwr2, ymax=upr2,y=NULL), alpha=0.35, fill = c("orange"),show.legend=FALSE) +
geom_line(data=gdata,aes(x=xx,y=mean),colour="gray25",linetype="dashed",size=1,show.legend=FALSE)+
theme_bw()
ggplot(normdata,aes(x=x1,y=y))+ geom_point(colour="#de2d26",size=1,alpha=0.35)+
geom_point(size=1.5,colour="red3")+
geom_ribbon(data=gdata,aes(x=xx,ymin=lwr1, ymax=upr1), alpha=0.95, fill=c("orange3"),show.legend=FALSE) +
geom_ribbon(data=gdata,aes(x=xx,ymin=lwr2, ymax=upr2), alpha=0.35, fill = c("orange"),show.legend=FALSE) +
geom_line(data=gdata,aes(x=xx,y=mean),colour="gray25",linetype="dashed",size=1,show.legend=FALSE)+
theme_bw()
ggplot(normdata,aes(x=x1,y=y))+ geom_point(colour="#de2d26",size=1,alpha=0.35)+
geom_point(size=1.5,colour="red3")+
geom_ribbon(data=gdata,aes(x=xx,ymin=lwr1, ymax=upr1,y=NULL), alpha=0.95, fill=c("orange3"),show.legend=FALSE) +
geom_ribbon(data=gdata,aes(x=xx,ymin=lwr2, ymax=upr2,y=NULL), alpha=0.35, fill = c("orange"),show.legend=FALSE) +
geom_line(data=gdata,aes(x=xx,y=mean),colour="gray25",linetype="dashed",size=1,show.legend=FALSE)+
theme_bw()
approx_CI(c(14,18,21))
14+log(1-0.95)/3
10+log(1-0.95)/3
log(1-0.95)
10+log(1-0.95)/100
10+log(1-0.95)/1000
10+log(1-0.95)/10000
10+log(1-0.95)/100
10+log(1-0.95)/10
10+log(1-0.95)/1
14+log(1-0.95)/3
